{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":89659,"databundleVersionId":11522106,"sourceType":"competition"},{"sourceId":224423433,"sourceType":"kernelVersion"},{"sourceId":104453,"sourceType":"modelInstanceVersion","modelInstanceId":72256,"modelId":76277}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#| default_exp core","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:24:36.075830Z","iopub.execute_input":"2025-04-05T03:24:36.076156Z","iopub.status.idle":"2025-04-05T03:24:36.079924Z","shell.execute_reply.started":"2025-04-05T03:24:36.076130Z","shell.execute_reply":"2025-04-05T03:24:36.079087Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#| export\n\nimport concurrent\nimport io\nimport logging\nimport re\nimport re2\n\nimport cairosvg\nimport kagglehub\nimport torch\nfrom lxml import etree\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForLanguageModeling,\n)\n\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:30:47.319095Z","iopub.execute_input":"2025-04-05T03:30:47.319406Z","iopub.status.idle":"2025-04-05T03:30:47.323652Z","shell.execute_reply.started":"2025-04-05T03:30:47.319379Z","shell.execute_reply":"2025-04-05T03:30:47.322826Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"svg_constraints = kagglehub.package_import('metric/svg-constraints')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:24:58.803809Z","iopub.execute_input":"2025-04-05T03:24:58.804320Z","iopub.status.idle":"2025-04-05T03:24:59.022507Z","shell.execute_reply.started":"2025-04-05T03:24:58.804286Z","shell.execute_reply":"2025-04-05T03:24:59.021717Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# FineTune Model with SFT \n\n> this is the stage 1, I have obtained the dataset from huggingface","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()\nfrom datasets import load_dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:24:59.023934Z","iopub.execute_input":"2025-04-05T03:24:59.024220Z","iopub.status.idle":"2025-04-05T03:24:59.757293Z","shell.execute_reply.started":"2025-04-05T03:24:59.024189Z","shell.execute_reply":"2025-04-05T03:24:59.756595Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef1edb5e9454c379aab96056f436216"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# the following dataset is curated and picked from huggingface, I will finetune my model based off this\n\nds = load_dataset(\"thesantatitan/deepseek-svg-dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:25:08.826182Z","iopub.execute_input":"2025-04-05T03:25:08.826487Z","iopub.status.idle":"2025-04-05T03:25:12.359760Z","shell.execute_reply.started":"2025-04-05T03:25:08.826459Z","shell.execute_reply":"2025-04-05T03:25:12.359104Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/422 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87f3c320a0d647bca147fdd870fb6bb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/5.86M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7673c659f1a549b899ed3dd11a219117"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/316k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc0a6c9a0dae40fdbed463e41e4b7caa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dccdf03936c240dba1cb16989bc432cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ef477953eba414e98d7c7a74b373914"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"ds['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:25:12.360676Z","iopub.execute_input":"2025-04-05T03:25:12.360926Z","iopub.status.idle":"2025-04-05T03:25:12.366104Z","shell.execute_reply.started":"2025-04-05T03:25:12.360905Z","shell.execute_reply":"2025-04-05T03:25:12.365368Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'prompt': \"Generate svg code for an image that looks like: a black background with a white and red flower. Don't use markdown just give svg code\\n\",\n 'completion': '\\n<reasoning>\\n\\nAlright, so the user is asking for an SVG code that creates an image with a black background and a white and red flower. They specified not to use markdown and just provide the SVG code. \\n\\nFirst, I need to structure the SVG properly. The basic structure includes the <svg> tag with width and height attributes. I\\'ll set it to 400x400 for a square canvas.\\n\\nNext, the background. I\\'ll use a <rect> element covering the entire canvas with a black fill.\\n\\nNow, for the flower. I\\'ll need multiple layers: a white petal layer, a red center, and stems. \\n\\nThe petals can be created using circles. I\\'ll position them around the center point (200,200) at different angles using transform attributes. Each petal will be a circle with a white fill and a subtle stroke for texture.\\n\\nThe center of the flower will be another circle, smaller and red. This adds the vibrant center.\\n\\nStems can be represented with rectangles. I\\'ll place them at the bottom and center, extending upwards to give the illusion of holding the flower.\\n\\nI\\'ll make sure all elements are positioned correctly and adjust the stroke widths for a more natural look. Testing with different numbers of petals and their positions to ensure symmetry and a cohesive design.\\n\\nFinally, I\\'ll compile all these elements within the SVG structure, ensuring proper nesting and attributes. Then, format it as per the user\\'s request, placing the code within the <generated_svg> tags without any markdown.\\n\\n</reasoning>\\n<generated_svg><?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<svg width=\"400\" height=\"400\" viewBox=\"0 0 400 400\" xmlns=\"http://www.w3.org/2000/svg\">\\n  <rect width=\"400\" height=\"400\" fill=\"#000000\"/>\\n  \\n  <!-- Flower petals -->\\n  <circle cx=\"200\" cy=\"200\" r=\"50\" fill=\"#FFFFFF\" stroke=\"#FFFFFF\" stroke-width=\"2\">\\n    <animate attributeName=\"transform\" dur=\"3s\" repeatCount=\"indefinite\" from=\"rotate(0 200 200)\" to=\"rotate(360 200 200)\" />\\n  </circle>\\n  \\n  <!-- Red flower center -->\\n  <circle cx=\"200\" cy=\"200\" r=\"25\" fill=\"#FF0000\"/>\\n  \\n  <!-- Flower stem -->\\n  <rect x=\"195\" y=\"250\" width=\"10\" height=\"150\" fill=\"#FFFFFF\" stroke=\"#666666\" stroke-width=\"2\"/>\\n</svg>\\n</generated_svg>\\n            '}"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_dataset, test_dataset = ds['train'], ds['test']\ntrain_dataset, test_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:25:14.513969Z","iopub.execute_input":"2025-04-05T03:25:14.514277Z","iopub.status.idle":"2025-04-05T03:25:14.519222Z","shell.execute_reply.started":"2025-04-05T03:25:14.514250Z","shell.execute_reply":"2025-04-05T03:25:14.518429Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['prompt', 'completion'],\n     num_rows: 4750\n }),\n Dataset({\n     features: ['prompt', 'completion'],\n     num_rows: 250\n }))"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Preprocessing Dataset \n> by removing unnecessary tags from the output generated","metadata":{}},{"cell_type":"code","source":"def preprocess_dataset(example):\n    \"\"\"\n    Removes <reasoning> sections and <generated_svg> tags from the completion.\n    \"\"\"\n    text_prompt_output = example['completion']\n    text_prompt_output = re.sub(r\"<reasoning>.*?</reasoning>\\n?\", \"\", text_prompt_output, flags=re.DOTALL)\n    text_prompt_output = re.sub(r\"</?generated_svg>\", \"\", text_prompt_output)\n    example['completion'] = text_prompt_output.strip()\n    return example\n\n# 3. Apply Cleaning to Train and Test\nclean_train_dataset = train_dataset.map(preprocess_dataset)\nclean_test_dataset = test_dataset.map(preprocess_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:25:16.383644Z","iopub.execute_input":"2025-04-05T03:25:16.383997Z","iopub.status.idle":"2025-04-05T03:25:16.831712Z","shell.execute_reply.started":"2025-04-05T03:25:16.383966Z","shell.execute_reply":"2025-04-05T03:25:16.830889Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be5717f8363d4743a54ca7c50cb86837"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"537dc414b15d4b0fab0a3c05f94ad28c"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"clean_train_dataset, clean_test_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:25:18.384458Z","iopub.execute_input":"2025-04-05T03:25:18.384799Z","iopub.status.idle":"2025-04-05T03:25:18.389803Z","shell.execute_reply.started":"2025-04-05T03:25:18.384768Z","shell.execute_reply":"2025-04-05T03:25:18.388909Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['prompt', 'completion'],\n     num_rows: 4750\n }),\n Dataset({\n     features: ['prompt', 'completion'],\n     num_rows: 250\n }))"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## Training Code\n\n> the following is finetuning the model using SFT techniques from huggingface","metadata":{}},{"cell_type":"code","source":"model_path = kagglehub.model_download('google/gemma-2/Transformers/gemma-2-9b-it/2')\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    device_map=\"auto\",\n    quantization_config=quantization_config\n)\n\n# Prepare model for k-bit LoRA training\nmodel = prepare_model_for_kbit_training(model)\n\n# Define LoRA Config\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Gemma supports all 4 attention heads\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\n# Apply LoRA\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:25:21.118251Z","iopub.execute_input":"2025-04-05T03:25:21.118528Z","iopub.status.idle":"2025-04-05T03:27:06.518415Z","shell.execute_reply.started":"2025-04-05T03:25:21.118506Z","shell.execute_reply":"2025-04-05T03:27:06.517555Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a43f4bf5679f4b2bbd6329e6b10ff1de"}},"metadata":{}},{"name":"stdout","text":"trainable params: 8,945,664 || all params: 9,250,651,648 || trainable%: 0.0967\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ===============================\n# 4. Tokenizer + Special SVG Tokens\n# ===============================\nspecial_tokens = [\"<svg>\", \"</svg>\", \"<circle>\", \"<rect>\", \"fill=\", \"stroke=\", \"d=\", \"path\", \"cx=\", \"cy=\"]\ntokenizer.add_tokens(special_tokens)\nmodel.resize_token_embeddings(len(tokenizer))\n\n# ===============================\n# 5. Tokenization Function\n# ===============================\ndef tokenize(example):\n    prompt = example[\"prompt\"]\n    svg = example[\"completion\"]\n    input_text = f\"### Prompt:\\n{prompt}\\n### SVG:\\n{svg}\"\n    tokenized = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=512)\n    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n    return tokenized\n\ntokenized_train = clean_train_dataset.map(tokenize, batched=False)\ntokenized_test = clean_test_dataset.map(tokenize, batched=False)\n\n# ===============================\n# 6. Data Collator\n# ===============================\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n# ===============================\n# 7. TrainingArguments (fixed)\n# ===============================\ntraining_args = TrainingArguments(\n    output_dir=\"./svg-gemma-lora\",\n    run_name=\"svg-gemma-run\",                 # avoids wandb name conflict\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    num_train_epochs=3,\n    fp16=True,\n    logging_steps=100,\n    save_steps=500,\n    eval_steps=500,\n    save_total_limit=2,\n    logging_dir=\"./logs\",\n    eval_strategy=\"epoch\",                   # updated from deprecated `evaluation_strategy`\n)\n\n# ===============================\n# 8. Trainer with label_names + no tokenizer arg\n# ===============================\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_test,\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T03:31:34.180692Z","iopub.execute_input":"2025-04-05T03:31:34.181080Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"## Save the loaded model \n\n> saving the loaded model","metadata":{}},{"cell_type":"code","source":"# Save model and tokenizer\ntrainer.save_model(\"./svg-model\")                 # Saves model weights/config\ntokenizer.save_pretrained(\"./svg-model\")         # Saves tokenizer vocab + config\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main Class Model\n\n> This is the main model class which is chosen for prediction","metadata":{}},{"cell_type":"code","source":"#| export\nimport concurrent\nimport io\nimport logging\nimport re\nimport re2\n\nimport cairosvg\nimport kagglehub\nimport torch\nfrom lxml import etree\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nsvg_constraints = kagglehub.package_import('metric/svg-constraints')\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass Model:\n    def __init__(self):\n         # Quantization Configuration\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_use_double_quant=True,\n            bnb_4bit_compute_dtype=torch.float16,\n        )\n        self.model_path = kagglehub.model_download('google/gemma-2/Transformers/gemma-2-9b-it/2')\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n        self.model = AutoModelForCausalLM.from_pretrained(\n            self.model_path,\n            device_map=\"auto\",\n            quantization_config=quantization_config,\n        )\n        self.prompt_template = \"\"\"Generate SVG code to visually represent the following text description, while respecting the given constraints.\n<constraints>\n* **Allowed Elements:** `svg`, `path`, `circle`, `rect`, `ellipse`, `line`, `polyline`, `polygon`, `g`, `linearGradient`, `radialGradient`, `stop`, `defs`\n* **Allowed Attributes:** `viewBox`, `width`, `height`, `fill`, `stroke`, `stroke-width`, `d`, `cx`, `cy`, `r`, `x`, `y`, `rx`, `ry`, `x1`, `y1`, `x2`, `y2`, `points`, `transform`, `opacity`\n</constraints>\n\n<example>\n<description>\"A red circle with a blue square inside\"</description>\n```svg\n<svg viewBox=\"0 0 256 256\" width=\"256\" height=\"256\">\n  <circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/>\n  <rect x=\"30\" y=\"30\" width=\"40\" height=\"40\" fill=\"blue\"/>\n</svg>\n```\n</example>\n\n\nPlease ensure that the generated SVG code is well-formed, valid, and strictly adheres to these constraints. Focus on a clear and concise representation of the input description within the given limitations. Always give the complete SVG code with nothing omitted. Never use an ellipsis.\n\n<description>\"{}\"</description>\n```svg\n<svg viewBox=\"0 0 256 256\" width=\"256\" height=\"256\">\n\"\"\"\n        self.default_svg = \"\"\"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\" /></svg>\"\"\"\n        self.constraints = svg_constraints.SVGConstraints()\n        self.timeout_seconds = 90\n\n    # You could try increasing `max_new_tokens`\n    def predict(self, description: str, max_new_tokens=512) -> str:\n        def generate_svg():\n            try:\n                prompt = self.prompt_template.format(description)\n                inputs = self.tokenizer(text=prompt, return_tensors=\"pt\").to(DEVICE)\n\n                with torch.no_grad():\n                    output = self.model.generate(\n                        **inputs,\n                        max_new_tokens=max_new_tokens,\n                        do_sample=True,\n                        temperature=0.7,\n                        top_p=0.9\n                    )\n\n                output_decoded = self.tokenizer.decode(output[0], skip_special_tokens=True)\n                logging.debug('Output decoded from model: %s', output_decoded)\n\n                matches = re.findall(r\"<svg.*?</svg>\", output_decoded, re.DOTALL | re.IGNORECASE)\n                if matches:\n                    svg = matches[-1]\n                else:\n                    return self.default_svg\n\n                logging.debug('Unprocessed SVG: %s', svg)\n                svg = self.enforce_constraints(svg)\n                logging.debug('Processed SVG: %s', svg)\n                # Ensure the generated code can be converted by cairosvg\n                cairosvg.svg2png(bytestring=svg.encode('utf-8'))\n                return svg\n            except Exception as e:\n                logging.error('Exception during SVG generation: %s', e)\n                return self.default_svg\n\n        # Execute SVG generation in a new thread to enforce time constraints\n        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n            future = executor.submit(generate_svg)\n            try:\n                return future.result(timeout=self.timeout_seconds)\n            except concurrent.futures.TimeoutError:\n                logging.warning(\"Prediction timed out after %s seconds.\", self.timeout_seconds)\n                return self.default_svg\n            except Exception as e:\n                logging.error(f\"An unexpected error occurred: {e}\")\n                return self.default_svg\n\n    def enforce_constraints(self, svg_string: str) -> str:\n        \"\"\"Enforces constraints on an SVG string, removing disallowed elements\n        and attributes.\n\n        Parameters\n        ----------\n        svg_string : str\n            The SVG string to process.\n\n        Returns\n        -------\n        str\n            The processed SVG string, or the default SVG if constraints\n            cannot be satisfied.\n        \"\"\"\n        logging.info('Sanitizing SVG...')\n\n        try:\n            parser = etree.XMLParser(remove_blank_text=True, remove_comments=True)\n            root = etree.fromstring(svg_string, parser=parser)\n        except etree.ParseError as e:\n            logging.error('SVG Parse Error: %s. Returning default SVG.', e)\n            return self.default_svg\n    \n        elements_to_remove = []\n        for element in root.iter():\n            tag_name = etree.QName(element.tag).localname\n    \n            # Remove disallowed elements\n            if tag_name not in self.constraints.allowed_elements:\n                elements_to_remove.append(element)\n                continue  # Skip attribute checks for removed elements\n    \n            # Remove disallowed attributes\n            attrs_to_remove = []\n            for attr in element.attrib:\n                attr_name = etree.QName(attr).localname\n                if (\n                    attr_name\n                    not in self.constraints.allowed_elements[tag_name]\n                    and attr_name\n                    not in self.constraints.allowed_elements['common']\n                ):\n                    attrs_to_remove.append(attr)\n    \n            for attr in attrs_to_remove:\n                element.attrib[attr] = 'default_value'\n                logging.debug(\n                    'Attribute \"%s\" for element \"%s\" not allowed. Removing.',\n                    attr,\n                    tag_name,\n                )\n                del element.attrib[attr]\n    \n            # Check and remove invalid href attributes\n            for attr, value in element.attrib.items():\n                 if etree.QName(attr).localname == 'href' and not value.startswith('#'):\n                    logging.debug(\n                        'Removing invalid href attribute in element \"%s\".', tag_name\n                    )\n                    del element.attrib[attr]\n\n            # Validate path elements to help ensure SVG conversion\n            if tag_name == 'path':\n                d_attribute = element.get('d')\n                if not d_attribute:\n                    logging.warning('Path element is missing \"d\" attribute. Removing path.')\n                    elements_to_remove.append(element)\n                    continue # Skip further checks for this removed element\n                # Use regex to validate 'd' attribute format\n                # path_regex = re2.compile(\n                #     r'^'  # Start of string\n                #     r'(?:'  # Non-capturing group for each command + numbers block\n                #     r'[MmZzLlHhVvCcSsQqTtAa]'  # Valid SVG path commands (adjusted to exclude extra letters)\n                #     r'\\s*'  # Optional whitespace after command\n                #     r'(?:'  # Non-capturing group for optional numbers\n                #     r'-?\\d+(?:\\.\\d+)?(?:[Ee][+-]?\\d+)?'  # First number\n                #     r'(?:[\\s,]+-?\\d+(?:\\.\\d+)?(?:[Ee][+-]?\\d+)?)*'  # Subsequent numbers with mandatory separator(s)\n                #     r')?'  # Numbers are optional (e.g. for Z command)\n                #     r'\\s*'  # Optional whitespace after numbers/command block\n                #     r')+'  # One or more command blocks\n                #     r'\\s*'  # Optional trailing whitespace\n                #     r'$'  # End of string\n                # )\n                path_regex = re2.compile(r'^[MmLlHhVvCcSsQqTtAaZz][0-9,\\.\\-\\s]*$')\n\n                if not path_regex.match(d_attribute):\n                    logging.warning(\n                        'Path element has malformed \"d\" attribute format. Removing path.'\n                    )\n                    elements_to_remove.append(element)\n                    continue\n                logging.debug('Path element \"d\" attribute validated (regex check).')\n        \n        # Remove elements marked for removal\n        for element in elements_to_remove:\n            if element.getparent() is not None:\n                element.getparent().remove(element)\n                logging.debug('Removed element: %s', element.tag)\n\n        try:\n            cleaned_svg_string = etree.tostring(root, encoding='unicode')\n            return cleaned_svg_string\n        except ValueError as e:\n            logging.error(\n                'SVG could not be sanitized to meet constraints: %s', e\n            )\n            return self.default_svg","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\nimport polars as pl\n\ntrain_path = kagglehub.competition_download('drawing-with-llms', 'train.csv')\ntrain = pl.read_csv(train_path)\n\ntrain.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import SVG\n\nmodel = Model()\nsvg = model.predict('Moon surrounded by stars')\n\nprint(svg)\ndisplay(SVG(svg))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}